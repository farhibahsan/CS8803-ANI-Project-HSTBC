{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import librosa\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from Datasets.SimpleDataset import SimpleDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary containing file path and its label ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_label_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220672,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'file_to_label_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m label \u001b[39m=\u001b[39m m[\u001b[39m2\u001b[39m]\n\u001b[0;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_call\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m label \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_song\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m label:\n\u001b[1;32m---> 79\u001b[0m     file_to_label_dict[file_out] \u001b[39m=\u001b[39m label\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file_to_label_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Modified from:\n",
    "\n",
    "\"\"\"\n",
    "Created by Francisco Bravo Sanchez July 2021\n",
    "This scripts reads the NIPS4B wav files and splits them according to the\n",
    "csv annotations from NIPS4Bplus (Morfi V, Bas Y, Pamula H, Glotin H,\n",
    "Stowell D. 2019. NIPS4Bplus: a richly annotated birdsong audio dataset.\n",
    "PeerJ Comput. Sci. 5:e223 http://doi.org/10.7717/peerj-cs.223)\n",
    "\n",
    "NIPS4B wav files:\n",
    "http://sabiod.univ-tln.fr/nips4b/media/birds/NIPS4B_BIRD_CHALLENGE_TRAIN_TEST_WAV.tar.gz\n",
    "\n",
    "NIPS4Bplus annotations:\n",
    "https://doi.org/10.6084/m9.figshare.6798548\n",
    "\n",
    "Instructions\n",
    "https://github.com/fbravosanchez/NIPS4Bplus#readme\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Set directories\n",
    "#path to NIPS4B_BIRD wav files\n",
    "wav_path = \"Data\\\\wav\\\\train\"\n",
    "#path to NIPS4Bplus csv annotation files\n",
    "csv_path = \"Data\\\\temporal_annotations_nips4b\"\n",
    "#output path for generated cut files\n",
    "output_path = \"Data\\\\cutfiles\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "\n",
    "#read csv label file list\n",
    "lbl_files = pd.DataFrame(glob.glob(os.path.join(csv_path , '')+ '*.csv'))\n",
    "lbl_files.columns = ['csv']\n",
    "lbl_files['wav'] = 'nips4b_birds_trainfile' + lbl_files['csv'].str[-7:-4]\n",
    "\n",
    "\n",
    "#process by csv file\n",
    "for i, j in lbl_files.iterrows():\n",
    "\n",
    "    #skip empty files\n",
    "    try:\n",
    "        k = pd.read_csv(j['csv'], header=None)\n",
    "        tags = True\n",
    "    except pd.errors.EmptyDataError:\n",
    "        tags = False\n",
    "\n",
    "    #for each valid csv file process wavefile\n",
    "    if tags:\n",
    "        [signal, fs] = sf.read(os.path.join(wav_path , '') + j['wav'] + '.wav')\n",
    "        signal = signal.astype(np.float64)\n",
    "        # print(signal.shape)\n",
    "\n",
    "        # Signal normalization\n",
    "        signal = signal/np.abs(np.max(signal))\n",
    "\n",
    "        #cut signal according to tag\n",
    "        for l, m in k.iterrows():\n",
    "            beg_sig = int(m[0]*fs)\n",
    "            end_sig = int((m[0]+m[1])*fs)\n",
    "            signal_cut = signal[beg_sig:end_sig]\n",
    "\n",
    "            # Save cut signal as a new wavefile\n",
    "            file_out = os.path.join(output_path, '') + str(j['wav']) +'_'+ str(l) + '.wav'\n",
    "            sf.write(file_out, signal_cut, fs)\n",
    "\n",
    "\n",
    "            # Add to dictionary if it is a bird call            \n",
    "            label = m[2]\n",
    "            if \"_call\" in label or \"_song\" in label:\n",
    "                file_to_label_dict[file_out] = label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the file->label dictionary so we don't have to run that again\n",
    "**NOTE: v1 version of the dict has _call and _song specifications removed, v2 has them still in (e.g. in v1 you would have Erirub and Erirub, in v2 you would have Erirub_call, Erirub_song)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle Successful\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pickles/filelabeldictv2.pkl', 'wb') as fp:\n",
    "    pickle.dump(file_to_label_dict, fp)\n",
    "    print(\"Pickle Successful\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded\n"
     ]
    }
   ],
   "source": [
    "with open('pickles/filelabeldictv2.pkl', 'rb') as fp:\n",
    "    file_to_label_dict = pickle.load(fp)\n",
    "    print(\"Pickle loaded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset from file label dict #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels into class indices ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables_int = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(file_to_label_dict.values())\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels_int = le.transform(labels)\n",
    "\n",
    "keys = list(file_to_label_dict.keys())\n",
    "\n",
    "file_to_class_int = dict(zip(keys, labels_int))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle Labels_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle Successful\n"
     ]
    }
   ],
   "source": [
    "with open('./pickles/labels_int.pkl', 'wb') as fp:\n",
    "    pickle.dump(labels_int, fp)\n",
    "    print(\"Pickle Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded\n"
     ]
    }
   ],
   "source": [
    "with open('pickles/labels_int.pkl', 'rb') as fp:\n",
    "    labels_int = pickle.load(fp)\n",
    "    print(\"Pickle loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 20 20 ... 57 57 57]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "num_classes = np.max(labels_int)\n",
    "label_binarizer = preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit(range(max(labels_int)+1))\n",
    "one_hot_labels = label_binarizer.transform(labels_int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling of one hots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle Successful\n"
     ]
    }
   ],
   "source": [
    "with open('./pickles/one_hot.pkl', 'wb') as fp:\n",
    "    pickle.dump(one_hot_labels, fp)\n",
    "    print(\"Pickle Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded\n"
     ]
    }
   ],
   "source": [
    "with open('pickles/one_hot.pkl', 'rb') as fp:\n",
    "    one_hot_labels = pickle.load(fp)\n",
    "    print(\"Pickle loaded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert audio files to a simple numerical representation for the baseline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio import load\n",
    "\n",
    "for file in keys:\n",
    "# audio file is decoded on the fly\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert audio files into wav2vec embeddings ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2Model: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\cutfiles\\nips4b_birds_trainfile001_1.wav\n",
      "Hidden state shape: (768,)\n",
      "Data\\cutfiles\\nips4b_birds_trainfile001_2.wav\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1). Kernel size: (2). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m# apply the model to the input array from wav\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 22\u001b[0m     outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[39m# extract last hidden state, compute average, convert to numpy\u001b[39;00m\n\u001b[0;32m     25\u001b[0m last_hidden_states \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlast_hidden_state\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\ani\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1297\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[1;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1292\u001b[0m output_hidden_states \u001b[39m=\u001b[39m (\n\u001b[0;32m   1293\u001b[0m     output_hidden_states \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39moutput_hidden_states\n\u001b[0;32m   1294\u001b[0m )\n\u001b[0;32m   1295\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1297\u001b[0m extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_extractor(input_values)\n\u001b[0;32m   1298\u001b[0m extract_features \u001b[39m=\u001b[39m extract_features\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m   1300\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1301\u001b[0m     \u001b[39m# compute reduced attention_mask corresponding to feature vectors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\ani\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:456\u001b[0m, in \u001b[0;36mWav2Vec2FeatureEncoder.forward\u001b[1;34m(self, input_values)\u001b[0m\n\u001b[0;32m    451\u001b[0m         hidden_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    452\u001b[0m             create_custom_forward(conv_layer),\n\u001b[0;32m    453\u001b[0m             hidden_states,\n\u001b[0;32m    454\u001b[0m         )\n\u001b[0;32m    455\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m         hidden_states \u001b[39m=\u001b[39m conv_layer(hidden_states)\n\u001b[0;32m    458\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\ani\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:306\u001b[0m, in \u001b[0;36mWav2Vec2NoLayerNormConvLayer.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[1;32m--> 306\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(hidden_states)\n\u001b[0;32m    307\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(hidden_states)\n\u001b[0;32m    308\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1). Kernel size: (2). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Modified from https://bagustris.wordpress.com/2022/08/23/acoustic-feature-extraction-with-transformers/\n",
    "'''\n",
    "\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "# load model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "for file in keys:\n",
    "# audio file is decoded on the fly\n",
    "    print(file)\n",
    "    array, fs = librosa.load(file, sr=16000)\n",
    "    # print(len(array))\n",
    "    input = processor(array.squeeze(), sampling_rate=fs, return_tensors=\"pt\")\n",
    "\n",
    "    # apply the model to the input array from wav\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input)\n",
    "\n",
    "    # extract last hidden state, compute average, convert to numpy\n",
    "    last_hidden_states = outputs.last_hidden_state.squeeze().mean(axis=0).numpy()\n",
    "    print(f\"Hidden state shape: {last_hidden_states.shape}\")\n",
    "    features.append(last_hidden_states)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the datapoint list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle Successful\n"
     ]
    }
   ],
   "source": [
    "with open('./pickles/datapoints.pkl', 'wb') as fp:\n",
    "    pickle.dump(features, fp)\n",
    "    print(\"Pickle Successful\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datapoint list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded\n",
      "torch.Size([5459, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "with open('pickles/datapoints.pkl', 'rb') as fp:\n",
    "    features = pickle.load(fp)\n",
    "    print(\"Pickle loaded\")\n",
    "\n",
    "features = np.array(features)\n",
    "features = torch.from_numpy(features).unsqueeze(1)\n",
    "print(features.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing that datset creates properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "# features = np.array(features)\n",
    "# features = torch.from_numpy(features).unsqueeze(1)\n",
    "# print(features.shape)\n",
    "test = SimpleDataset(features, one_hot_labels)\n",
    "test_loader = DataLoader(test, batch_size=5, shuffle=True)\n",
    "\n",
    "data, label = next(iter(test_loader))\n",
    "print(data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Neural Network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# import soundfile as sf\n",
    "import numpy as np\n",
    "import pickle\n",
    "# from sklearn import preprocessing\n",
    "# from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "# import librosa\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from Datasets.SimpleDataset import SimpleDataset\n",
    "# import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded\n",
      "Pickle loaded\n",
      "(5459, 28, 28)\n",
      "torch.Size([5459, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "labels_int = None\n",
    "features = None\n",
    "\n",
    "with open('pickles/labels_int.pkl', 'rb') as fp:\n",
    "    labels_int = pickle.load(fp)\n",
    "    print(\"Pickle loaded\")\n",
    "\n",
    "with open('pickles/datapoints.pkl', 'rb') as fp:\n",
    "    features = pickle.load(fp)\n",
    "    print(\"Pickle loaded\")\n",
    "\n",
    "features = np.array(features)\n",
    "features = np.pad(features, ((0, 0), (0, 16)))\n",
    "features = np.array(np.split(features, 28, axis=1))\n",
    "features = features.reshape((features.shape[1], features.shape[0], -1))\n",
    "print(features.shape)\n",
    "features = torch.from_numpy(features).unsqueeze(1)\n",
    "features = features.repeat(1, 3, 1, 1)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Thats/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod_Resnet(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=59, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from resnet1d.resnet1d import ResNet1D\n",
    "from model.test_net import CNN\n",
    "from model.Mod_Resnet import Mod_Resnet\n",
    "\n",
    "# model = ResNet1D(1, 2, 3, 1, 1, 8, 59).to(device)\n",
    "model = Mod_Resnet().to(device)\n",
    "model.fc = nn.Linear(512, 59) # assuming that the fc7 layer has 512 neurons, otherwise change it \n",
    "model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(labels_int))\n",
    "bird_call_dataset = SimpleDataset(features, labels_int)\n",
    "train_size = int(0.8*len(bird_call_dataset))\n",
    "test_size = len(bird_call_dataset) - train_size\n",
    "train_set, test_set = random_split(bird_call_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Try different learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Try different optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y = y.type(torch.LongTensor)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        # print(X.shape)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            y = y.type(torch.LongTensor)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Valid Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 12.516876  [    0/ 4367]\n",
      "loss: 8.134588  [  800/ 4367]\n",
      "loss: 4.776534  [ 1600/ 4367]\n",
      "loss: 4.498838  [ 2400/ 4367]\n",
      "loss: 4.286469  [ 3200/ 4367]\n",
      "loss: 4.251761  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 4.1%, Avg loss: 10.626030 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.294632  [    0/ 4367]\n",
      "loss: 4.394954  [  800/ 4367]\n",
      "loss: 3.476369  [ 1600/ 4367]\n",
      "loss: 4.528619  [ 2400/ 4367]\n",
      "loss: 4.345991  [ 3200/ 4367]\n",
      "loss: 4.274442  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 5.3%, Avg loss: 4.697166 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.266598  [    0/ 4367]\n",
      "loss: 3.819308  [  800/ 4367]\n",
      "loss: 4.057833  [ 1600/ 4367]\n",
      "loss: 4.642469  [ 2400/ 4367]\n",
      "loss: 3.445732  [ 3200/ 4367]\n",
      "loss: 4.598976  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 5.9%, Avg loss: 4.290036 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.126251  [    0/ 4367]\n",
      "loss: 3.865439  [  800/ 4367]\n",
      "loss: 4.347623  [ 1600/ 4367]\n",
      "loss: 4.036867  [ 2400/ 4367]\n",
      "loss: 4.310561  [ 3200/ 4367]\n",
      "loss: 4.693190  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 7.1%, Avg loss: 4.335949 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.925314  [    0/ 4367]\n",
      "loss: 4.224727  [  800/ 4367]\n",
      "loss: 4.053840  [ 1600/ 4367]\n",
      "loss: 3.852044  [ 2400/ 4367]\n",
      "loss: 3.451601  [ 3200/ 4367]\n",
      "loss: 3.998393  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 4.9%, Avg loss: 4.223996 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4.183569  [    0/ 4367]\n",
      "loss: 3.892967  [  800/ 4367]\n",
      "loss: 3.945213  [ 1600/ 4367]\n",
      "loss: 3.893198  [ 2400/ 4367]\n",
      "loss: 3.854289  [ 3200/ 4367]\n",
      "loss: 5.371637  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 6.8%, Avg loss: 4.272236 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.825808  [    0/ 4367]\n",
      "loss: 3.915629  [  800/ 4367]\n",
      "loss: 3.842574  [ 1600/ 4367]\n",
      "loss: 4.065042  [ 2400/ 4367]\n",
      "loss: 3.827713  [ 3200/ 4367]\n",
      "loss: 3.909960  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 7.1%, Avg loss: 4.245738 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.469399  [    0/ 4367]\n",
      "loss: 3.863204  [  800/ 4367]\n",
      "loss: 4.543152  [ 1600/ 4367]\n",
      "loss: 4.274209  [ 2400/ 4367]\n",
      "loss: 4.093504  [ 3200/ 4367]\n",
      "loss: 4.232429  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 7.2%, Avg loss: 3.991053 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 4.216138  [    0/ 4367]\n",
      "loss: 3.680097  [  800/ 4367]\n",
      "loss: 3.968418  [ 1600/ 4367]\n",
      "loss: 4.542141  [ 2400/ 4367]\n",
      "loss: 3.662046  [ 3200/ 4367]\n",
      "loss: 3.663137  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 8.6%, Avg loss: 3.918489 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.630888  [    0/ 4367]\n",
      "loss: 3.240261  [  800/ 4367]\n",
      "loss: 4.028704  [ 1600/ 4367]\n",
      "loss: 4.210659  [ 2400/ 4367]\n",
      "loss: 3.901586  [ 3200/ 4367]\n",
      "loss: 3.697615  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 8.3%, Avg loss: 3.910187 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 4.424520  [    0/ 4367]\n",
      "loss: 4.526828  [  800/ 4367]\n",
      "loss: 4.044277  [ 1600/ 4367]\n",
      "loss: 3.236570  [ 2400/ 4367]\n",
      "loss: 4.463057  [ 3200/ 4367]\n",
      "loss: 3.725335  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.0%, Avg loss: 3.888747 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 4.392903  [    0/ 4367]\n",
      "loss: 3.887383  [  800/ 4367]\n",
      "loss: 4.838147  [ 1600/ 4367]\n",
      "loss: 4.125107  [ 2400/ 4367]\n",
      "loss: 4.135825  [ 3200/ 4367]\n",
      "loss: 3.580135  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.8%, Avg loss: 3.906279 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 3.365650  [    0/ 4367]\n",
      "loss: 3.467933  [  800/ 4367]\n",
      "loss: 4.630092  [ 1600/ 4367]\n",
      "loss: 4.217231  [ 2400/ 4367]\n",
      "loss: 4.171902  [ 3200/ 4367]\n",
      "loss: 2.932448  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.1%, Avg loss: 3.887084 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 3.685552  [    0/ 4367]\n",
      "loss: 4.003933  [  800/ 4367]\n",
      "loss: 4.136151  [ 1600/ 4367]\n",
      "loss: 3.412507  [ 2400/ 4367]\n",
      "loss: 4.258382  [ 3200/ 4367]\n",
      "loss: 4.211485  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.2%, Avg loss: 3.865453 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 3.501878  [    0/ 4367]\n",
      "loss: 4.199021  [  800/ 4367]\n",
      "loss: 3.419208  [ 1600/ 4367]\n",
      "loss: 4.134363  [ 2400/ 4367]\n",
      "loss: 4.436494  [ 3200/ 4367]\n",
      "loss: 4.563059  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 8.2%, Avg loss: 3.867920 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 3.421327  [    0/ 4367]\n",
      "loss: 3.827863  [  800/ 4367]\n",
      "loss: 3.844679  [ 1600/ 4367]\n",
      "loss: 3.945012  [ 2400/ 4367]\n",
      "loss: 3.870827  [ 3200/ 4367]\n",
      "loss: 3.756850  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.6%, Avg loss: 3.860572 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 4.276872  [    0/ 4367]\n",
      "loss: 3.368898  [  800/ 4367]\n",
      "loss: 3.799457  [ 1600/ 4367]\n",
      "loss: 3.778087  [ 2400/ 4367]\n",
      "loss: 3.858154  [ 3200/ 4367]\n",
      "loss: 3.557668  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.3%, Avg loss: 3.862714 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 3.672233  [    0/ 4367]\n",
      "loss: 3.771967  [  800/ 4367]\n",
      "loss: 3.560740  [ 1600/ 4367]\n",
      "loss: 4.060468  [ 2400/ 4367]\n",
      "loss: 4.073730  [ 3200/ 4367]\n",
      "loss: 4.037994  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 8.5%, Avg loss: 3.883497 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 4.154752  [    0/ 4367]\n",
      "loss: 3.743858  [  800/ 4367]\n",
      "loss: 3.157336  [ 1600/ 4367]\n",
      "loss: 4.151611  [ 2400/ 4367]\n",
      "loss: 4.445300  [ 3200/ 4367]\n",
      "loss: 3.463799  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 8.8%, Avg loss: 3.847104 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 4.071166  [    0/ 4367]\n",
      "loss: 3.724680  [  800/ 4367]\n",
      "loss: 3.893970  [ 1600/ 4367]\n",
      "loss: 3.521597  [ 2400/ 4367]\n",
      "loss: 3.800770  [ 3200/ 4367]\n",
      "loss: 3.674327  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.1%, Avg loss: 3.847247 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 3.622471  [    0/ 4367]\n",
      "loss: 3.763975  [  800/ 4367]\n",
      "loss: 3.460291  [ 1600/ 4367]\n",
      "loss: 4.278775  [ 2400/ 4367]\n",
      "loss: 3.700086  [ 3200/ 4367]\n",
      "loss: 3.989967  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.8%, Avg loss: 3.906530 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 3.438093  [    0/ 4367]\n",
      "loss: 3.586630  [  800/ 4367]\n",
      "loss: 3.540235  [ 1600/ 4367]\n",
      "loss: 3.421113  [ 2400/ 4367]\n",
      "loss: 4.034492  [ 3200/ 4367]\n",
      "loss: 3.568716  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.7%, Avg loss: 3.838301 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 4.211148  [    0/ 4367]\n",
      "loss: 2.762095  [  800/ 4367]\n",
      "loss: 3.656672  [ 1600/ 4367]\n",
      "loss: 4.268798  [ 2400/ 4367]\n",
      "loss: 3.395662  [ 3200/ 4367]\n",
      "loss: 3.688149  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.9%, Avg loss: 3.842385 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 3.222661  [    0/ 4367]\n",
      "loss: 3.492414  [  800/ 4367]\n",
      "loss: 4.503974  [ 1600/ 4367]\n",
      "loss: 4.119142  [ 2400/ 4367]\n",
      "loss: 3.845698  [ 3200/ 4367]\n",
      "loss: 3.695238  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 8.2%, Avg loss: 3.813146 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 3.740907  [    0/ 4367]\n",
      "loss: 4.296171  [  800/ 4367]\n",
      "loss: 4.058259  [ 1600/ 4367]\n",
      "loss: 3.843336  [ 2400/ 4367]\n",
      "loss: 3.170281  [ 3200/ 4367]\n",
      "loss: 4.148553  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.6%, Avg loss: 3.825347 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 3.311378  [    0/ 4367]\n",
      "loss: 4.006894  [  800/ 4367]\n",
      "loss: 3.278729  [ 1600/ 4367]\n",
      "loss: 3.285187  [ 2400/ 4367]\n",
      "loss: 4.156274  [ 3200/ 4367]\n",
      "loss: 3.824279  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 8.4%, Avg loss: 3.810336 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.775340  [    0/ 4367]\n",
      "loss: 3.455718  [  800/ 4367]\n",
      "loss: 3.706926  [ 1600/ 4367]\n",
      "loss: 3.646612  [ 2400/ 4367]\n",
      "loss: 3.556691  [ 3200/ 4367]\n",
      "loss: 4.506390  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.7%, Avg loss: 3.823204 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 3.649603  [    0/ 4367]\n",
      "loss: 3.993825  [  800/ 4367]\n",
      "loss: 3.955153  [ 1600/ 4367]\n",
      "loss: 3.691158  [ 2400/ 4367]\n",
      "loss: 4.157227  [ 3200/ 4367]\n",
      "loss: 3.747856  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.0%, Avg loss: 3.823566 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 3.711379  [    0/ 4367]\n",
      "loss: 5.164977  [  800/ 4367]\n",
      "loss: 3.961477  [ 1600/ 4367]\n",
      "loss: 3.885703  [ 2400/ 4367]\n",
      "loss: 4.231838  [ 3200/ 4367]\n",
      "loss: 3.930041  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.7%, Avg loss: 3.850574 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 3.854940  [    0/ 4367]\n",
      "loss: 3.642736  [  800/ 4367]\n",
      "loss: 3.549982  [ 1600/ 4367]\n",
      "loss: 4.196750  [ 2400/ 4367]\n",
      "loss: 3.715997  [ 3200/ 4367]\n",
      "loss: 4.255476  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.0%, Avg loss: 3.814018 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 4.037536  [    0/ 4367]\n",
      "loss: 4.131043  [  800/ 4367]\n",
      "loss: 3.110082  [ 1600/ 4367]\n",
      "loss: 3.985758  [ 2400/ 4367]\n",
      "loss: 4.195931  [ 3200/ 4367]\n",
      "loss: 4.023367  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 8.9%, Avg loss: 3.840753 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 3.532502  [    0/ 4367]\n",
      "loss: 3.777776  [  800/ 4367]\n",
      "loss: 3.857720  [ 1600/ 4367]\n",
      "loss: 3.603719  [ 2400/ 4367]\n",
      "loss: 4.048813  [ 3200/ 4367]\n",
      "loss: 3.709558  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.6%, Avg loss: 3.824074 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 3.725990  [    0/ 4367]\n",
      "loss: 3.200042  [  800/ 4367]\n",
      "loss: 3.999315  [ 1600/ 4367]\n",
      "loss: 4.315436  [ 2400/ 4367]\n",
      "loss: 4.073064  [ 3200/ 4367]\n",
      "loss: 4.219580  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.8%, Avg loss: 3.806385 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 4.033070  [    0/ 4367]\n",
      "loss: 3.915226  [  800/ 4367]\n",
      "loss: 3.313831  [ 1600/ 4367]\n",
      "loss: 3.506054  [ 2400/ 4367]\n",
      "loss: 3.425125  [ 3200/ 4367]\n",
      "loss: 3.468442  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.4%, Avg loss: 3.802816 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 3.354569  [    0/ 4367]\n",
      "loss: 3.717874  [  800/ 4367]\n",
      "loss: 3.938921  [ 1600/ 4367]\n",
      "loss: 4.073248  [ 2400/ 4367]\n",
      "loss: 4.196848  [ 3200/ 4367]\n",
      "loss: 3.255177  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.5%, Avg loss: 3.808214 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 3.837835  [    0/ 4367]\n",
      "loss: 3.862402  [  800/ 4367]\n",
      "loss: 4.071822  [ 1600/ 4367]\n",
      "loss: 3.592863  [ 2400/ 4367]\n",
      "loss: 3.598868  [ 3200/ 4367]\n",
      "loss: 2.895364  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.3%, Avg loss: 3.822546 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 3.334668  [    0/ 4367]\n",
      "loss: 3.724817  [  800/ 4367]\n",
      "loss: 3.362128  [ 1600/ 4367]\n",
      "loss: 3.910245  [ 2400/ 4367]\n",
      "loss: 3.873466  [ 3200/ 4367]\n",
      "loss: 3.722448  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.1%, Avg loss: 3.820893 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 4.043300  [    0/ 4367]\n",
      "loss: 2.693623  [  800/ 4367]\n",
      "loss: 3.476421  [ 1600/ 4367]\n",
      "loss: 3.029671  [ 2400/ 4367]\n",
      "loss: 3.504505  [ 3200/ 4367]\n",
      "loss: 3.963953  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.1%, Avg loss: 3.852552 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 3.728378  [    0/ 4367]\n",
      "loss: 3.523492  [  800/ 4367]\n",
      "loss: 3.860966  [ 1600/ 4367]\n",
      "loss: 3.355165  [ 2400/ 4367]\n",
      "loss: 3.541534  [ 3200/ 4367]\n",
      "loss: 3.486702  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.2%, Avg loss: 3.796612 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 4.438323  [    0/ 4367]\n",
      "loss: 3.422847  [  800/ 4367]\n",
      "loss: 4.007859  [ 1600/ 4367]\n",
      "loss: 2.747571  [ 2400/ 4367]\n",
      "loss: 3.407568  [ 3200/ 4367]\n",
      "loss: 3.957799  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.3%, Avg loss: 3.805060 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 4.098983  [    0/ 4367]\n",
      "loss: 3.484388  [  800/ 4367]\n",
      "loss: 2.526300  [ 1600/ 4367]\n",
      "loss: 3.779960  [ 2400/ 4367]\n",
      "loss: 4.105124  [ 3200/ 4367]\n",
      "loss: 3.738724  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 12.6%, Avg loss: 3.832251 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 3.447669  [    0/ 4367]\n",
      "loss: 3.336791  [  800/ 4367]\n",
      "loss: 3.569931  [ 1600/ 4367]\n",
      "loss: 3.840030  [ 2400/ 4367]\n",
      "loss: 3.538751  [ 3200/ 4367]\n",
      "loss: 4.009233  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 7.8%, Avg loss: 3.850021 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 3.597858  [    0/ 4367]\n",
      "loss: 3.471802  [  800/ 4367]\n",
      "loss: 3.741657  [ 1600/ 4367]\n",
      "loss: 3.289624  [ 2400/ 4367]\n",
      "loss: 4.298566  [ 3200/ 4367]\n",
      "loss: 3.504698  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.2%, Avg loss: 3.785075 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 3.589599  [    0/ 4367]\n",
      "loss: 3.210571  [  800/ 4367]\n",
      "loss: 5.012006  [ 1600/ 4367]\n",
      "loss: 3.711650  [ 2400/ 4367]\n",
      "loss: 3.147264  [ 3200/ 4367]\n",
      "loss: 4.033673  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.7%, Avg loss: 3.812168 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 3.666703  [    0/ 4367]\n",
      "loss: 3.285640  [  800/ 4367]\n",
      "loss: 3.578832  [ 1600/ 4367]\n",
      "loss: 3.417142  [ 2400/ 4367]\n",
      "loss: 4.061952  [ 3200/ 4367]\n",
      "loss: 3.921291  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 12.1%, Avg loss: 3.812051 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 3.636439  [    0/ 4367]\n",
      "loss: 3.534415  [  800/ 4367]\n",
      "loss: 3.213809  [ 1600/ 4367]\n",
      "loss: 3.296007  [ 2400/ 4367]\n",
      "loss: 4.051864  [ 3200/ 4367]\n",
      "loss: 3.449158  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.2%, Avg loss: 3.849837 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 3.474383  [    0/ 4367]\n",
      "loss: 3.144856  [  800/ 4367]\n",
      "loss: 3.102947  [ 1600/ 4367]\n",
      "loss: 3.469691  [ 2400/ 4367]\n",
      "loss: 3.575912  [ 3200/ 4367]\n",
      "loss: 4.014555  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.1%, Avg loss: 3.785998 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 3.632970  [    0/ 4367]\n",
      "loss: 3.663555  [  800/ 4367]\n",
      "loss: 3.586726  [ 1600/ 4367]\n",
      "loss: 3.520048  [ 2400/ 4367]\n",
      "loss: 3.695204  [ 3200/ 4367]\n",
      "loss: 3.013710  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 12.6%, Avg loss: 3.897994 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 3.712234  [    0/ 4367]\n",
      "loss: 3.951545  [  800/ 4367]\n",
      "loss: 3.361256  [ 1600/ 4367]\n",
      "loss: 3.681913  [ 2400/ 4367]\n",
      "loss: 3.032867  [ 3200/ 4367]\n",
      "loss: 3.505666  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.4%, Avg loss: 3.861295 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 3.814369  [    0/ 4367]\n",
      "loss: 3.849822  [  800/ 4367]\n",
      "loss: 3.318233  [ 1600/ 4367]\n",
      "loss: 3.480425  [ 2400/ 4367]\n",
      "loss: 3.805665  [ 3200/ 4367]\n",
      "loss: 3.307312  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.1%, Avg loss: 3.803393 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 2.915709  [    0/ 4367]\n",
      "loss: 3.503594  [  800/ 4367]\n",
      "loss: 3.907377  [ 1600/ 4367]\n",
      "loss: 3.193213  [ 2400/ 4367]\n",
      "loss: 3.542948  [ 3200/ 4367]\n",
      "loss: 2.731937  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.6%, Avg loss: 3.857147 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 3.458011  [    0/ 4367]\n",
      "loss: 3.553530  [  800/ 4367]\n",
      "loss: 3.922476  [ 1600/ 4367]\n",
      "loss: 3.460042  [ 2400/ 4367]\n",
      "loss: 3.782613  [ 3200/ 4367]\n",
      "loss: 3.046081  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.6%, Avg loss: 3.873614 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 3.452815  [    0/ 4367]\n",
      "loss: 3.731797  [  800/ 4367]\n",
      "loss: 3.852927  [ 1600/ 4367]\n",
      "loss: 3.961406  [ 2400/ 4367]\n",
      "loss: 3.530389  [ 3200/ 4367]\n",
      "loss: 3.084373  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.1%, Avg loss: 3.842242 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 3.704981  [    0/ 4367]\n",
      "loss: 3.288252  [  800/ 4367]\n",
      "loss: 4.459623  [ 1600/ 4367]\n",
      "loss: 3.345293  [ 2400/ 4367]\n",
      "loss: 3.594561  [ 3200/ 4367]\n",
      "loss: 4.337282  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.6%, Avg loss: 3.860022 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 3.928097  [    0/ 4367]\n",
      "loss: 3.499336  [  800/ 4367]\n",
      "loss: 3.287147  [ 1600/ 4367]\n",
      "loss: 3.020612  [ 2400/ 4367]\n",
      "loss: 4.011302  [ 3200/ 4367]\n",
      "loss: 3.209964  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.9%, Avg loss: 3.826208 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 3.451946  [    0/ 4367]\n",
      "loss: 3.610377  [  800/ 4367]\n",
      "loss: 3.569243  [ 1600/ 4367]\n",
      "loss: 4.077189  [ 2400/ 4367]\n",
      "loss: 3.628234  [ 3200/ 4367]\n",
      "loss: 4.503128  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.2%, Avg loss: 3.845530 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 3.772195  [    0/ 4367]\n",
      "loss: 3.470875  [  800/ 4367]\n",
      "loss: 4.398612  [ 1600/ 4367]\n",
      "loss: 3.374423  [ 2400/ 4367]\n",
      "loss: 3.711771  [ 3200/ 4367]\n",
      "loss: 3.644542  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.2%, Avg loss: 3.822639 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 3.431274  [    0/ 4367]\n",
      "loss: 4.329647  [  800/ 4367]\n",
      "loss: 3.745190  [ 1600/ 4367]\n",
      "loss: 4.274154  [ 2400/ 4367]\n",
      "loss: 4.349202  [ 3200/ 4367]\n",
      "loss: 3.828130  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.5%, Avg loss: 3.804032 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 3.760507  [    0/ 4367]\n",
      "loss: 3.211850  [  800/ 4367]\n",
      "loss: 3.368741  [ 1600/ 4367]\n",
      "loss: 3.003006  [ 2400/ 4367]\n",
      "loss: 3.541321  [ 3200/ 4367]\n",
      "loss: 4.001719  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.4%, Avg loss: 3.822058 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 4.219491  [    0/ 4367]\n",
      "loss: 2.860299  [  800/ 4367]\n",
      "loss: 2.745710  [ 1600/ 4367]\n",
      "loss: 4.071466  [ 2400/ 4367]\n",
      "loss: 3.851782  [ 3200/ 4367]\n",
      "loss: 4.198173  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.5%, Avg loss: 3.878302 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 4.066215  [    0/ 4367]\n",
      "loss: 3.757607  [  800/ 4367]\n",
      "loss: 4.246880  [ 1600/ 4367]\n",
      "loss: 3.924227  [ 2400/ 4367]\n",
      "loss: 3.687706  [ 3200/ 4367]\n",
      "loss: 4.439761  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.5%, Avg loss: 3.851135 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 3.657079  [    0/ 4367]\n",
      "loss: 3.632275  [  800/ 4367]\n",
      "loss: 3.042864  [ 1600/ 4367]\n",
      "loss: 3.193123  [ 2400/ 4367]\n",
      "loss: 3.874555  [ 3200/ 4367]\n",
      "loss: 3.457814  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.2%, Avg loss: 3.854859 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 3.808540  [    0/ 4367]\n",
      "loss: 3.774980  [  800/ 4367]\n",
      "loss: 3.461189  [ 1600/ 4367]\n",
      "loss: 3.538784  [ 2400/ 4367]\n",
      "loss: 4.345721  [ 3200/ 4367]\n",
      "loss: 3.555598  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.6%, Avg loss: 3.825860 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 4.605992  [    0/ 4367]\n",
      "loss: 4.059724  [  800/ 4367]\n",
      "loss: 2.952110  [ 1600/ 4367]\n",
      "loss: 3.102969  [ 2400/ 4367]\n",
      "loss: 3.610069  [ 3200/ 4367]\n",
      "loss: 4.174012  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 8.6%, Avg loss: 3.929179 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 3.534094  [    0/ 4367]\n",
      "loss: 3.597625  [  800/ 4367]\n",
      "loss: 3.758027  [ 1600/ 4367]\n",
      "loss: 3.636858  [ 2400/ 4367]\n",
      "loss: 3.287605  [ 3200/ 4367]\n",
      "loss: 4.067750  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.7%, Avg loss: 3.865070 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 3.500644  [    0/ 4367]\n",
      "loss: 3.700035  [  800/ 4367]\n",
      "loss: 3.405584  [ 1600/ 4367]\n",
      "loss: 3.493338  [ 2400/ 4367]\n",
      "loss: 3.355191  [ 3200/ 4367]\n",
      "loss: 4.546411  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.2%, Avg loss: 3.878306 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 3.256757  [    0/ 4367]\n",
      "loss: 3.512301  [  800/ 4367]\n",
      "loss: 3.513894  [ 1600/ 4367]\n",
      "loss: 4.212636  [ 2400/ 4367]\n",
      "loss: 3.346628  [ 3200/ 4367]\n",
      "loss: 4.039419  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.8%, Avg loss: 3.883847 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 3.451901  [    0/ 4367]\n",
      "loss: 3.121547  [  800/ 4367]\n",
      "loss: 2.993420  [ 1600/ 4367]\n",
      "loss: 4.078240  [ 2400/ 4367]\n",
      "loss: 4.596403  [ 3200/ 4367]\n",
      "loss: 3.395078  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.5%, Avg loss: 3.867580 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 3.700799  [    0/ 4367]\n",
      "loss: 2.654698  [  800/ 4367]\n",
      "loss: 3.506892  [ 1600/ 4367]\n",
      "loss: 3.590241  [ 2400/ 4367]\n",
      "loss: 3.328137  [ 3200/ 4367]\n",
      "loss: 4.513351  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.2%, Avg loss: 3.877000 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 3.746334  [    0/ 4367]\n",
      "loss: 3.323538  [  800/ 4367]\n",
      "loss: 2.871864  [ 1600/ 4367]\n",
      "loss: 3.322245  [ 2400/ 4367]\n",
      "loss: 3.641146  [ 3200/ 4367]\n",
      "loss: 4.348340  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.8%, Avg loss: 3.876296 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 3.684987  [    0/ 4367]\n",
      "loss: 3.504456  [  800/ 4367]\n",
      "loss: 2.926227  [ 1600/ 4367]\n",
      "loss: 4.435558  [ 2400/ 4367]\n",
      "loss: 3.541869  [ 3200/ 4367]\n",
      "loss: 3.623969  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.8%, Avg loss: 3.905768 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 4.267109  [    0/ 4367]\n",
      "loss: 3.835568  [  800/ 4367]\n",
      "loss: 3.455174  [ 1600/ 4367]\n",
      "loss: 3.053072  [ 2400/ 4367]\n",
      "loss: 3.388983  [ 3200/ 4367]\n",
      "loss: 3.212390  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.6%, Avg loss: 3.866730 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 3.865455  [    0/ 4367]\n",
      "loss: 3.606954  [  800/ 4367]\n",
      "loss: 3.622351  [ 1600/ 4367]\n",
      "loss: 3.392207  [ 2400/ 4367]\n",
      "loss: 5.052542  [ 3200/ 4367]\n",
      "loss: 3.961419  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.1%, Avg loss: 3.865499 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 3.783826  [    0/ 4367]\n",
      "loss: 3.570381  [  800/ 4367]\n",
      "loss: 4.177256  [ 1600/ 4367]\n",
      "loss: 3.324571  [ 2400/ 4367]\n",
      "loss: 3.583981  [ 3200/ 4367]\n",
      "loss: 4.580250  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.2%, Avg loss: 3.901125 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 3.609789  [    0/ 4367]\n",
      "loss: 3.677419  [  800/ 4367]\n",
      "loss: 3.145548  [ 1600/ 4367]\n",
      "loss: 3.793387  [ 2400/ 4367]\n",
      "loss: 3.549496  [ 3200/ 4367]\n",
      "loss: 3.606623  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.6%, Avg loss: 3.850064 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 4.006382  [    0/ 4367]\n",
      "loss: 3.635062  [  800/ 4367]\n",
      "loss: 3.520655  [ 1600/ 4367]\n",
      "loss: 2.932190  [ 2400/ 4367]\n",
      "loss: 4.328025  [ 3200/ 4367]\n",
      "loss: 3.590594  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.6%, Avg loss: 3.927211 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 3.429984  [    0/ 4367]\n",
      "loss: 3.246315  [  800/ 4367]\n",
      "loss: 4.351311  [ 1600/ 4367]\n",
      "loss: 3.381019  [ 2400/ 4367]\n",
      "loss: 4.480142  [ 3200/ 4367]\n",
      "loss: 4.074133  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.9%, Avg loss: 3.882030 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 3.849513  [    0/ 4367]\n",
      "loss: 4.502879  [  800/ 4367]\n",
      "loss: 3.808445  [ 1600/ 4367]\n",
      "loss: 3.191446  [ 2400/ 4367]\n",
      "loss: 4.234199  [ 3200/ 4367]\n",
      "loss: 3.305690  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.3%, Avg loss: 3.879807 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 3.230761  [    0/ 4367]\n",
      "loss: 3.560836  [  800/ 4367]\n",
      "loss: 3.744955  [ 1600/ 4367]\n",
      "loss: 3.656472  [ 2400/ 4367]\n",
      "loss: 3.341977  [ 3200/ 4367]\n",
      "loss: 3.185554  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.1%, Avg loss: 3.964134 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 3.673825  [    0/ 4367]\n",
      "loss: 3.897818  [  800/ 4367]\n",
      "loss: 3.506362  [ 1600/ 4367]\n",
      "loss: 3.229982  [ 2400/ 4367]\n",
      "loss: 3.383561  [ 3200/ 4367]\n",
      "loss: 3.183706  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.2%, Avg loss: 3.891375 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 3.404243  [    0/ 4367]\n",
      "loss: 3.345512  [  800/ 4367]\n",
      "loss: 4.014924  [ 1600/ 4367]\n",
      "loss: 3.485385  [ 2400/ 4367]\n",
      "loss: 3.806315  [ 3200/ 4367]\n",
      "loss: 3.027194  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.2%, Avg loss: 3.944682 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 4.046164  [    0/ 4367]\n",
      "loss: 3.360120  [  800/ 4367]\n",
      "loss: 3.333860  [ 1600/ 4367]\n",
      "loss: 4.379858  [ 2400/ 4367]\n",
      "loss: 3.016761  [ 3200/ 4367]\n",
      "loss: 3.019521  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.4%, Avg loss: 3.869676 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 3.437603  [    0/ 4367]\n",
      "loss: 3.949744  [  800/ 4367]\n",
      "loss: 3.275453  [ 1600/ 4367]\n",
      "loss: 3.621405  [ 2400/ 4367]\n",
      "loss: 3.998026  [ 3200/ 4367]\n",
      "loss: 3.978865  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.3%, Avg loss: 3.839138 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 4.084652  [    0/ 4367]\n",
      "loss: 3.615031  [  800/ 4367]\n",
      "loss: 4.281079  [ 1600/ 4367]\n",
      "loss: 3.921978  [ 2400/ 4367]\n",
      "loss: 3.950217  [ 3200/ 4367]\n",
      "loss: 3.724601  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.3%, Avg loss: 3.920406 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 4.066034  [    0/ 4367]\n",
      "loss: 3.199652  [  800/ 4367]\n",
      "loss: 3.328013  [ 1600/ 4367]\n",
      "loss: 3.466708  [ 2400/ 4367]\n",
      "loss: 3.452847  [ 3200/ 4367]\n",
      "loss: 3.260211  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.2%, Avg loss: 3.926327 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 4.118610  [    0/ 4367]\n",
      "loss: 3.710851  [  800/ 4367]\n",
      "loss: 3.891859  [ 1600/ 4367]\n",
      "loss: 3.710694  [ 2400/ 4367]\n",
      "loss: 3.603673  [ 3200/ 4367]\n",
      "loss: 3.371393  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.0%, Avg loss: 3.881888 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 3.670616  [    0/ 4367]\n",
      "loss: 3.642204  [  800/ 4367]\n",
      "loss: 3.708191  [ 1600/ 4367]\n",
      "loss: 3.096078  [ 2400/ 4367]\n",
      "loss: 4.515842  [ 3200/ 4367]\n",
      "loss: 3.011921  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.6%, Avg loss: 3.865176 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 3.279288  [    0/ 4367]\n",
      "loss: 3.884024  [  800/ 4367]\n",
      "loss: 3.104956  [ 1600/ 4367]\n",
      "loss: 3.282206  [ 2400/ 4367]\n",
      "loss: 2.838553  [ 3200/ 4367]\n",
      "loss: 3.951285  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.4%, Avg loss: 3.989163 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 3.382770  [    0/ 4367]\n",
      "loss: 3.869792  [  800/ 4367]\n",
      "loss: 3.207131  [ 1600/ 4367]\n",
      "loss: 4.180464  [ 2400/ 4367]\n",
      "loss: 3.475099  [ 3200/ 4367]\n",
      "loss: 3.462306  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.8%, Avg loss: 3.905472 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 3.284292  [    0/ 4367]\n",
      "loss: 3.877901  [  800/ 4367]\n",
      "loss: 3.372071  [ 1600/ 4367]\n",
      "loss: 2.799427  [ 2400/ 4367]\n",
      "loss: 3.346661  [ 3200/ 4367]\n",
      "loss: 3.405299  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.7%, Avg loss: 3.883149 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 3.788264  [    0/ 4367]\n",
      "loss: 3.705185  [  800/ 4367]\n",
      "loss: 3.312793  [ 1600/ 4367]\n",
      "loss: 4.430577  [ 2400/ 4367]\n",
      "loss: 3.507123  [ 3200/ 4367]\n",
      "loss: 4.234550  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.0%, Avg loss: 3.897155 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 3.935514  [    0/ 4367]\n",
      "loss: 3.729198  [  800/ 4367]\n",
      "loss: 4.266491  [ 1600/ 4367]\n",
      "loss: 3.089172  [ 2400/ 4367]\n",
      "loss: 3.634607  [ 3200/ 4367]\n",
      "loss: 3.864646  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.3%, Avg loss: 3.963319 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 4.118580  [    0/ 4367]\n",
      "loss: 3.417334  [  800/ 4367]\n",
      "loss: 3.628050  [ 1600/ 4367]\n",
      "loss: 3.202027  [ 2400/ 4367]\n",
      "loss: 2.943757  [ 3200/ 4367]\n",
      "loss: 4.082522  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.6%, Avg loss: 3.953394 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 3.470131  [    0/ 4367]\n",
      "loss: 3.401907  [  800/ 4367]\n",
      "loss: 3.960181  [ 1600/ 4367]\n",
      "loss: 3.089925  [ 2400/ 4367]\n",
      "loss: 4.389802  [ 3200/ 4367]\n",
      "loss: 4.016071  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 12.5%, Avg loss: 3.898091 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 4.032425  [    0/ 4367]\n",
      "loss: 4.302270  [  800/ 4367]\n",
      "loss: 3.903013  [ 1600/ 4367]\n",
      "loss: 3.965155  [ 2400/ 4367]\n",
      "loss: 3.266100  [ 3200/ 4367]\n",
      "loss: 2.959617  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.4%, Avg loss: 3.890003 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 3.698074  [    0/ 4367]\n",
      "loss: 4.201123  [  800/ 4367]\n",
      "loss: 3.445751  [ 1600/ 4367]\n",
      "loss: 3.951722  [ 2400/ 4367]\n",
      "loss: 3.328092  [ 3200/ 4367]\n",
      "loss: 3.443479  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.9%, Avg loss: 3.915068 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 2.900589  [    0/ 4367]\n",
      "loss: 3.607121  [  800/ 4367]\n",
      "loss: 3.572962  [ 1600/ 4367]\n",
      "loss: 3.499090  [ 2400/ 4367]\n",
      "loss: 3.542428  [ 3200/ 4367]\n",
      "loss: 3.625784  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 13.7%, Avg loss: 3.856436 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 3.926996  [    0/ 4367]\n",
      "loss: 3.891232  [  800/ 4367]\n",
      "loss: 4.783521  [ 1600/ 4367]\n",
      "loss: 3.376346  [ 2400/ 4367]\n",
      "loss: 3.626463  [ 3200/ 4367]\n",
      "loss: 4.046238  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 9.8%, Avg loss: 4.010423 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 3.635044  [    0/ 4367]\n",
      "loss: 3.590707  [  800/ 4367]\n",
      "loss: 3.132886  [ 1600/ 4367]\n",
      "loss: 3.453889  [ 2400/ 4367]\n",
      "loss: 4.414989  [ 3200/ 4367]\n",
      "loss: 4.780041  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 10.2%, Avg loss: 3.906151 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 3.648508  [    0/ 4367]\n",
      "loss: 3.969496  [  800/ 4367]\n",
      "loss: 3.399981  [ 1600/ 4367]\n",
      "loss: 3.467175  [ 2400/ 4367]\n",
      "loss: 3.892429  [ 3200/ 4367]\n",
      "loss: 3.392244  [ 4000/ 4367]\n",
      "Valid Error: \n",
      " Accuracy: 11.3%, Avg loss: 3.897916 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
